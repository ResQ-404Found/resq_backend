from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from app.rag.counseling.vectorstore import build_counseling_vectorstore
import os

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

counseling_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì¹œì ˆí•œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.  
ì•„ë˜ contextë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ê³ ë¯¼ì— ê³µê°í•˜ê³  ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.  
contextì— ë‹µì´ ì—†ë‹¤ë©´ LLMì˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•´ë„ ë©ë‹ˆë‹¤.  
ë‹¨, ì „ë¬¸ì ì¸ ì¹˜ë£Œë‚˜ ì˜í•™ì  ì§„ë‹¨ì€ ëŒ€ì‹ í•˜ì§€ ë§ˆì„¸ìš”.  

<context>
{context}
</context>

ğŸ™‹ ì§ˆë¬¸: {input}
""")

llm = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-3.5-turbo-0125", temperature=0.7)

def build_counseling_chain(pdf_path: str):
    vectorstore = build_counseling_vectorstore(pdf_path)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    document_chain = create_stuff_documents_chain(llm, counseling_prompt)
    return create_retrieval_chain(retriever, document_chain)
